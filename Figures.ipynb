{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19fc614ea90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from src.models import models\n",
    "from src.models import model as mainmodel\n",
    "from src.models import modelConv2d\n",
    "from src.models import modelineal\n",
    "from src.models import decoders\n",
    "from src import loss_func\n",
    "from src import train\n",
    "from src import loader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src import optimizer_Factory as of\n",
    "import Data.genData as genData\n",
    "from src import custom_plots as cp\n",
    "from src import Visual_utils as vu\n",
    "import torchvision\n",
    "import wandb\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:2000\"\n",
    "torch.cuda.empty_cache() \n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "torch.manual_seed(42)\n",
    "\n",
    "t,a = genData.generateDynamics(max=1.0, min = -1.0)\n",
    "sr = 20\n",
    "dt_sim = t[1]-t[0]\n",
    "dt = dt_sim*sr\n",
    "print(\"dt\", dt)\n",
    "train_dataloader, test_dataloader, train_x, val_x  = loader.getLoader(a,type=\"Motion\", \n",
    "                                                                      split = True,  \n",
    "                                                                      dt=dt_sim, \n",
    "                                                                      nInFrames = 10,\n",
    "                                                                      sr = sr ,  \n",
    "                                                                      noise=False, \n",
    "                                                                      shapeType='simple')\n",
    "\n",
    "\n",
    "\n",
    "latentEncoder = mainmodel.EndPhys(dt = dt,  \n",
    "                                pmodel = \"Damped_oscillation\",\n",
    "                                init_phys = 5.0, \n",
    "                                initw=True)\n",
    "\n",
    "latentEncoder, log  = train.train(latentEncoder, \n",
    "                                train_dataloader, \n",
    "                                test_dataloader,                                 \n",
    "                                loss_name='latent_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 20, 1, 50, 50)\n",
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\aleja\\Documents\\TUDelft\\Repository\\Vphys\\wandb\\run-20240517_120721-awqxnnen</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alejandro_c/Vphysics-Project-IC/runs/awqxnnen' target=\"_blank\">exp_EndPhys_17_05_24_12</a></strong> to <a href='https://wandb.ai/alejandro_c/Vphysics-Project-IC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alejandro_c/Vphysics-Project-IC' target=\"_blank\">https://wandb.ai/alejandro_c/Vphysics-Project-IC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alejandro_c/Vphysics-Project-IC/runs/awqxnnen' target=\"_blank\">https://wandb.ai/alejandro_c/Vphysics-Project-IC/runs/awqxnnen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss \t training loss: 2.8186405386243547 \t validation loss: 3.7593058347702026\n",
      "epoch: 20 \t training loss: 0.7605711093970707 \t validation loss: 1.574905276298523\n",
      "epoch: 40 \t training loss: 0.27603737477745327 \t validation loss: 0.7893719673156738\n",
      "epoch: 60 \t training loss: 0.20977070209171092 \t validation loss: 0.662215381860733\n",
      "epoch: 80 \t training loss: 0.2026361422613263 \t validation loss: 0.6496551036834717\n",
      "epoch: 100 \t training loss: 0.20156666317156383 \t validation loss: 0.6532204151153564\n",
      "epoch: 120 \t training loss: 0.2053965660078185 \t validation loss: 0.6690738797187805\n",
      "epoch: 140 \t training loss: 0.2023406382650137 \t validation loss: 0.6608217060565948\n",
      "epoch: 160 \t training loss: 0.2017686183431319 \t validation loss: 0.662855714559555\n",
      "epoch: 180 \t training loss: 0.19217638977404153 \t validation loss: 0.6283492147922516\n",
      "epoch: 200 \t training loss: 0.21511290861027582 \t validation loss: 0.6894524395465851\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "torch.manual_seed(0)\n",
    "\n",
    "data_folder = np.load('Data/dataset_intensity.npy')\n",
    "data_train = data_folder\n",
    "print(data_train.shape)\n",
    "dt = 0.2\n",
    "train_dataloader, test_dataloader, train_x, val_x  = loader.getLoader_folder(data_train, split=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "latentEncoder = mainmodel.EndPhys(dt = dt,  \n",
    "                                pmodel = \"Damped_oscillation\",\n",
    "                                init_phys = 5.0, \n",
    "                                initw=True)\n",
    "\n",
    "latentEncoder, log  = train.train(latentEncoder, \n",
    "                                train_dataloader, \n",
    "                                test_dataloader,                                 \n",
    "                                loss_name='latent_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "torch.manual_seed(0)\n",
    "\n",
    "data_folder = np.load('Data/dataset_motion.npy')\n",
    "data_train = data_folder\n",
    "print(data_train.shape)\n",
    "dt = 0.2\n",
    "train_dataloader, test_dataloader, train_x, val_x  = loader.getLoader_folder(data_train, split=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "latentEncoder = mainmodel.EndPhys(dt = dt,  \n",
    "                                pmodel = \"Damped_oscillation\",\n",
    "                                init_phys = 5.0, \n",
    "                                initw=True)\n",
    "\n",
    "latentEncoder, log  = train.train(latentEncoder, \n",
    "                                train_dataloader, \n",
    "                                test_dataloader,                                 \n",
    "                                loss_name='latent_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "torch.manual_seed(0)\n",
    "\n",
    "data_folder = np.load('Data/dataset_Scale_nu.npy')\n",
    "data_train = data_folder\n",
    "print(data_train.shape)\n",
    "dt = 0.2\n",
    "train_dataloader, test_dataloader, train_x, val_x  = loader.getLoader_folder(data_train, split=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "latentEncoder = mainmodel.EndPhys(dt = dt,  \n",
    "                                pmodel = \"Damped_oscillation\",\n",
    "                                init_phys = 5.0, \n",
    "                                initw=True)\n",
    "\n",
    "latentEncoder, log  = train.train(latentEncoder, \n",
    "                                train_dataloader, \n",
    "                                test_dataloader,                                 \n",
    "                                loss_name='latent_loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
